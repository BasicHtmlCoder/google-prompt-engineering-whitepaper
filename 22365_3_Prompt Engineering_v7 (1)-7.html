<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="" xml:lang="">
<head>
<title>Page 7</title>

<meta http-equiv="Content-Type" content="text/html; charset=UTF-8"/>
<style type="text/css">
<!--
	p {margin: 0; padding: 0;}	.ft00{font-size:12px;font-family:ZENJOE+GoogleSansText-Medium;color:#80868b;}
	.ft01{font-size:17px;font-family:WGJRYK+GoogleSansText;color:#202124;}
	.ft02{font-size:10px;font-family:WGJRYK+GoogleSansText;color:#202124;}
	.ft03{font-size:36px;font-family:WGJRYK+GoogleSans;color:#202124;}
	.ft04{font-size:17px;line-height:26px;font-family:WGJRYK+GoogleSansText;color:#202124;}
-->
</style>
</head>
<body bgcolor="#A0A0A0" vlink="blue" link="blue">
<div id="page7-div" style="position:relative;width:918px;height:1188px;">
<img width="918" height="1188" src="22365_3_Prompt Engineering_v7 (1)007.png" alt="background image"/>
<p style="position:absolute;top:86px;left:108px;white-space:nowrap" class="ft00">Prompt&#160;Engineering</p>
<p style="position:absolute;top:1076px;left:108px;white-space:nowrap" class="ft00">February&#160;2025</p>
<p style="position:absolute;top:1076px;left:804px;white-space:nowrap" class="ft00">7</p>
<p style="position:absolute;top:197px;left:108px;white-space:nowrap" class="ft01">When you chat with the Gemini chatbot,</p>
<p style="position:absolute;top:198px;left:407px;white-space:nowrap" class="ft02">1</p>
<p style="position:absolute;top:197px;left:411px;white-space:nowrap" class="ft01">&#160;you basically write prompts, however this&#160;</p>
<p style="position:absolute;top:224px;left:108px;white-space:nowrap" class="ft04">whitepaper focuses on writing prompts for the Gemini model within Vertex AI or by using&#160;&#160;<br/>the API, because by prompting the model directly you will have access to the configuration&#160;<br/>such as temperature etc.</p>
<p style="position:absolute;top:332px;left:108px;white-space:nowrap" class="ft04">This whitepaper discusses prompt engineering in detail. We will look into the various&#160;<br/>prompting techniques to help you getting started and share tips and best practices to&#160;<br/>become a prompting expert. We will also discuss some of the challenges you can face&#160;&#160;<br/>while crafting prompts.</p>
<p style="position:absolute;top:488px;left:108px;white-space:nowrap" class="ft03"><b>Prompt&#160;engineering</b></p>
<p style="position:absolute;top:560px;left:108px;white-space:nowrap" class="ft04">Remember how an LLM works; it’s a prediction engine. The model takes sequential text as&#160;<br/>an input and then predicts what the following token should be, based on the data it was&#160;<br/>trained on. The LLM is operationalized to do this over and over again, adding the previously&#160;<br/>predicted token to the end of the sequential text for predicting the following token. The next&#160;<br/>token prediction is based on the relationship between what’s in the previous tokens and what&#160;<br/>the LLM has seen during its training.&#160;</p>
<p style="position:absolute;top:749px;left:108px;white-space:nowrap" class="ft04">When you write a prompt, you are attempting to set up the LLM to predict the right sequence&#160;<br/>of tokens. Prompt engineering is the process of designing high-quality prompts that guide&#160;<br/>LLMs to produce accurate outputs. This process involves tinkering to find the best prompt,&#160;<br/>optimizing prompt length, and evaluating a prompt’s writing style and structure in relation&#160;<br/>to the task. In the context of natural language processing and LLMs, a prompt is an input&#160;<br/>provided to the model to generate a response or prediction.</p>
</div>
</body>
</html>
