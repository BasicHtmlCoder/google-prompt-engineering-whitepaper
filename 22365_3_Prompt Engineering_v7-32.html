<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="" xml:lang="">

<head>
	<title>Page 32</title>

	<meta http-equiv="Content-Type" content="text/html; charset=UTF-8" />
	<style type="text/css">
		<!--
		p {
			margin: 0;
			padding: 0;
		}

		.ft00 {
			font-size: 12px;
			font-family: ZENJOE+GoogleSansText-Medium;
			color: #80868b;
		}

		.ft01 {
			font-size: 17px;
			font-family: WGJRYK+GoogleSansText;
			color: #202124;
		}

		.ft02 {
			font-size: 24px;
			font-family: WGJRYK+GoogleSans;
			color: #202124;
		}

		.ft03 {
			font-size: 10px;
			font-family: WGJRYK+GoogleSansText;
			color: #202124;
		}

		.ft04 {
			font-size: 17px;
			line-height: 26px;
			font-family: WGJRYK+GoogleSansText;
			color: #202124;
		}
		-->
	</style>
</head>

<body bgcolor="#A0A0A0" vlink="blue" link="blue">
	<div id="page32-div" style="position:relative;width:918px;height:1188px;">
		<img width="918" height="1188" src="22365_3_Prompt Engineering_v7032.png" alt="background image" />
		<p style="position:absolute;top:86px;left:108px;white-space:nowrap" class="ft00">Prompt&#160;Engineering</p>
		<p style="position:absolute;top:1076px;left:108px;white-space:nowrap" class="ft00">February&#160;2025</p>
		<p style="position:absolute;top:1076px;left:797px;white-space:nowrap" class="ft00">32</p>
		<p style="position:absolute;top:197px;left:108px;white-space:nowrap" class="ft04">In the best practices section
			of this chapter, we will learn some best practices specific to&#160;<br />Chain of thought prompting.</p>
		<p style="position:absolute;top:299px;left:108px;white-space:nowrap" class="ft02"><b>Self-consistency</b></p>
		<p style="position:absolute;top:359px;left:108px;white-space:nowrap" class="ft04">While large language models
			have shown impressive success in various NLP tasks, their&#160;<br />ability to reason is often seen as a
			limitation that cannot be overcome solely by increasing&#160;<br />model size. As we learned in the previous
			Chain of Thought prompting section, the model can&#160;<br />be prompted to generate reasoning steps like a
			human solving a problem. However CoT uses&#160;<br />a simple ‘greedy decoding’ strategy, limiting its
			effectiveness. Self-consistency</p>
		<p style="position:absolute;top:468px;left:700px;white-space:nowrap" class="ft03">11</p>
		<p style="position:absolute;top:467px;left:707px;white-space:nowrap" class="ft01">&#160;combines&#160;</p>
		<p style="position:absolute;top:494px;left:108px;white-space:nowrap" class="ft04">sampling and majority voting
			to generate diverse reasoning paths and select the most&#160;<br />consistent answer. It improves the
			accuracy and coherence of responses generated by LLMs.</p>
		<p style="position:absolute;top:575px;left:108px;white-space:nowrap" class="ft04">Self-consistency gives a
			pseudo-probability likelihood of an answer being correct, but&#160;<br />obviously has high costs.</p>
		<p style="position:absolute;top:656px;left:108px;white-space:nowrap" class="ft01">It follows the following
			steps:</p>
		<p style="position:absolute;top:696px;left:108px;white-space:nowrap" class="ft01">1.&#160;&#160;Generating
			diverse reasoning paths: The LLM is provided with the same prompt multiple&#160;</p>
		<p style="position:absolute;top:723px;left:129px;white-space:nowrap" class="ft04">times. A high temperature
			setting encourages the model to generate different reasoning&#160;<br />paths and perspectives on the
			problem.</p>
		<p style="position:absolute;top:791px;left:108px;white-space:nowrap" class="ft01">2.&#160;&#160;Extract the
			answer from each generated response.</p>
		<p style="position:absolute;top:831px;left:108px;white-space:nowrap" class="ft01">3.&#160;&#160;Choose the most
			common answer.</p>
		<p style="position:absolute;top:885px;left:108px;white-space:nowrap" class="ft04">Let’s look into an example of
			an email classification system, which classifies an email as&#160;<br />IMPORTANT or NOT IMPORTANT. A
			zero-shot chain of thought prompt will be sent to the LLM&#160;<br />multiple times, to see if the responses
			differ after each submit. Notice the friendly tone, the&#160;<br />word choice and the sarcasm that’s been
			used in the email. All this could trick the LLM.</p>
	</div>
</body>

</html>