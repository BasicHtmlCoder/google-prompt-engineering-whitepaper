<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="" xml:lang="">

<head>
	<title>Page 64</title>

	<meta http-equiv="Content-Type" content="text/html; charset=UTF-8" />
	<style type="text/css">
		<!--
		p {
			margin: 0;
			padding: 0;
		}

		.ft00 {
			font-size: 12px;
			font-family: ZENJOE+GoogleSansText-Medium;
			color: #80868b;
		}

		.ft01 {
			font-size: 24px;
			font-family: WGJRYK+GoogleSans;
			color: #202124;
		}

		.ft02 {
			font-size: 17px;
			font-family: WGJRYK+GoogleSansText;
			color: #202124;
		}

		.ft03 {
			font-size: 17px;
			line-height: 26px;
			font-family: WGJRYK+GoogleSansText;
			color: #202124;
		}
		-->
	</style>
</head>

<body bgcolor="#A0A0A0" vlink="blue" link="blue">
	<div id="page64-div" style="position:relative;width:918px;height:1188px;">
		<img width="918" height="1188" src="22365_3_Prompt Engineering_v7064.png" alt="background image" />
		<p style="position:absolute;top:86px;left:108px;white-space:nowrap" class="ft00">Prompt&#160;Engineering</p>
		<p style="position:absolute;top:1076px;left:108px;white-space:nowrap" class="ft00">February&#160;2025</p>
		<p style="position:absolute;top:1076px;left:796px;white-space:nowrap" class="ft00">64</p>
		<p style="position:absolute;top:198px;left:108px;white-space:nowrap" class="ft01"><b>CoT Best practices</b></p>
		<p style="position:absolute;top:258px;left:108px;white-space:nowrap" class="ft03">For CoT prompting, putting the
			answer after the reasoning is required because the&#160;<br />generation of the reasoning changes the tokens
			that the model gets when it predicts the&#160;<br />final answer.</p>
		<p style="position:absolute;top:366px;left:108px;white-space:nowrap" class="ft03">With CoT and self-consistency
			you need to be able to extract the final answer from your&#160;<br />prompt, separated from the
			reasoning.&#160;</p>
		<p style="position:absolute;top:447px;left:108px;white-space:nowrap" class="ft02">For CoT prompting, set the
			temperature to 0.</p>
		<p style="position:absolute;top:501px;left:108px;white-space:nowrap" class="ft03">Chain of thought prompting is
			based on greedy decoding, predicting the next word in a&#160;<br />sequence based on the highest probability
			assigned by the language model. Generally&#160;<br />speaking, when using reasoning, to come up with the
			final answer, there’s likely one single&#160;<br />correct answer. Therefore the temperature should always
			set to 0.&#160;</p>
		<p style="position:absolute;top:657px;left:108px;white-space:nowrap" class="ft01"><b>Document the various prompt
				attempts</b></p>
		<p style="position:absolute;top:717px;left:108px;white-space:nowrap" class="ft03">The last tip was mentioned
			before in this chapter, but we can’t stress enough how important&#160;<br />it is: document your prompt
			attempts in full detail so you can learn over time what went well&#160;<br />and what did not.&#160;</p>
		<p style="position:absolute;top:825px;left:108px;white-space:nowrap" class="ft03">Prompt outputs can differ
			across models, across sampling settings, and even across different&#160;<br />versions of the same model.
			Moreover, even across identical prompts to the same model,&#160;<br />small differences in output sentence
			formatting and word choice can occur. (For example, as&#160;<br />mentioned previously, if two tokens have
			the same predicted probability, ties may be broken&#160;<br />randomly. This can then impact subsequent
			predicted tokens.).</p>
	</div>
</body>

</html>