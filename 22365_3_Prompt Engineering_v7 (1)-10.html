<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="" xml:lang="">
<head>
<title>Page 10</title>

<meta http-equiv="Content-Type" content="text/html; charset=UTF-8"/>
<style type="text/css">
<!--
	p {margin: 0; padding: 0;}	.ft00{font-size:12px;font-family:ZENJOE+GoogleSansText-Medium;color:#80868b;}
	.ft01{font-size:17px;font-family:WGJRYK+GoogleSansText;color:#202124;}
	.ft02{font-size:21px;font-family:WGJRYK+GoogleSans;color:#202124;}
	.ft03{font-size:10px;font-family:WGJRYK+GoogleSansText;color:#202124;}
	.ft04{font-size:17px;font-family:WGJRYK+GoogleSansText;color:#202124;}
	.ft05{font-size:17px;line-height:26px;font-family:WGJRYK+GoogleSansText;color:#202124;}
-->
</style>
</head>
<body bgcolor="#A0A0A0" vlink="blue" link="blue">
<div id="page10-div" style="position:relative;width:918px;height:1188px;">
<img width="918" height="1188" src="22365_3_Prompt Engineering_v7 (1)010.png" alt="background image"/>
<p style="position:absolute;top:86px;left:108px;white-space:nowrap" class="ft00">Prompt&#160;Engineering</p>
<p style="position:absolute;top:1076px;left:108px;white-space:nowrap" class="ft00">February&#160;2025</p>
<p style="position:absolute;top:1076px;left:797px;white-space:nowrap" class="ft00">10</p>
<p style="position:absolute;top:197px;left:108px;white-space:nowrap" class="ft05">deterministic: the highest probability token is always selected (though note that if two tokens&#160;<br/>have the same highest predicted probability, depending on how tiebreaking is implemented&#160;<br/>you may not always get the same output with temperature 0).</p>
<p style="position:absolute;top:305px;left:108px;white-space:nowrap" class="ft05">Temperatures close to the max tend to create more random output. And as temperature gets&#160;<br/>higher and higher, all tokens become equally likely to be the next predicted token.</p>
<p style="position:absolute;top:386px;left:108px;white-space:nowrap" class="ft05">The Gemini temperature control can be understood in a similar way to the softmax function&#160;<br/>used in machine learning. A low temperature setting mirrors a low softmax temperature (T),&#160;<br/>emphasizing&#160;a&#160;single,&#160;preferred&#160;temperature&#160;with&#160;high&#160;certainty.&#160;A&#160;higher&#160;Gemini&#160;temperature&#160;<br/>setting is like a high softmax temperature, making a wider range of temperatures around&#160;<br/>the selected setting more acceptable. This increased uncertainty accommodates scenarios&#160;<br/>where a rigid, precise temperature may not be essential like for example when experimenting&#160;<br/>with&#160;creative&#160;outputs.</p>
<p style="position:absolute;top:626px;left:108px;white-space:nowrap" class="ft02"><b>Top-K&#160;and&#160;top-P</b></p>
<p style="position:absolute;top:683px;left:108px;white-space:nowrap" class="ft01">Top-K and top-P (also known as nucleus sampling)</p>
<p style="position:absolute;top:684px;left:487px;white-space:nowrap" class="ft03">4</p>
<p style="position:absolute;top:683px;left:493px;white-space:nowrap" class="ft01">&#160;are two sampling settings used in LLMs&#160;</p>
<p style="position:absolute;top:710px;left:108px;white-space:nowrap" class="ft05">to restrict the predicted next token to come from tokens with the top predicted probabilities.&#160;&#160;<br/>Like temperature, these sampling settings control the randomness and diversity of&#160;<br/>generated&#160;text.</p>
<p style="position:absolute;top:804px;left:108px;white-space:nowrap" class="ft01">•&#160;&#160;<b>Top-K</b>&#160;sampling selects the top K most likely tokens from the model’s predicted&#160;</p>
<p style="position:absolute;top:831px;left:129px;white-space:nowrap" class="ft05">distribution. The higher top-K, the more creative and varied the model’s output; the&#160;<br/>lower top-K, the more restive and factual the model’s output. A top-K of 1 is equivalent to&#160;<br/>greedy&#160;decoding.</p>
</div>
</body>
</html>
