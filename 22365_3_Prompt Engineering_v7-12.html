<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="" xml:lang="">

<head>
	<title>Page 12</title>

	<meta http-equiv="Content-Type" content="text/html; charset=UTF-8" />
	<style type="text/css">
		<!--
		p {
			margin: 0;
			padding: 0;
		}

		.ft00 {
			font-size: 12px;
			font-family: ZENJOE+GoogleSansText-Medium;
			color: #80868b;
		}

		.ft01 {
			font-size: 17px;
			font-family: WGJRYK+GoogleSansText;
			color: #202124;
		}

		.ft02 {
			font-size: 17px;
			font-family: WGJRYK+GoogleSansText;
			color: #202124;
		}

		.ft03 {
			font-size: 17px;
			line-height: 26px;
			font-family: WGJRYK+GoogleSansText;
			color: #202124;
		}
		-->
	</style>
</head>

<body bgcolor="#A0A0A0" vlink="blue" link="blue">
	<div id="page12-div" style="position:relative;width:918px;height:1188px;">
		<img width="918" height="1188" src="22365_3_Prompt Engineering_v7012.png" alt="background image" />
		<p style="position:absolute;top:86px;left:108px;white-space:nowrap" class="ft00">Prompt&#160;Engineering</p>
		<p style="position:absolute;top:1076px;left:108px;white-space:nowrap" class="ft00">February&#160;2025</p>
		<p style="position:absolute;top:1076px;left:798px;white-space:nowrap" class="ft00">12</p>
		<p style="position:absolute;top:197px;left:108px;white-space:nowrap" class="ft01">•&#160;&#160;If you set
			temperature to 0, top-K and top-P become irrelevant–the most probable&#160;</p>
		<p style="position:absolute;top:224px;left:129px;white-space:nowrap" class="ft03">token becomes the next token
			predicted. If you set temperature extremely high (above&#160;<br />1–generally into the 10s), temperature
			becomes irrelevant and whatever tokens make&#160;<br />it through the top-K and/or top-P criteria are then
			randomly sampled to choose a next&#160;<br />predicted&#160;token.</p>
		<p style="position:absolute;top:345px;left:108px;white-space:nowrap" class="ft01">•&#160;&#160;If you set top-K
			to 1, temperature and top-P become irrelevant. Only one token passes the&#160;</p>
		<p style="position:absolute;top:372px;left:129px;white-space:nowrap" class="ft03">top-K criteria, and that token
			is the next predicted token. If you set top-K extremely high,&#160;<br />like to the size of the LLM’s
			vocabulary, any token with a nonzero probability of being the&#160;<br />next token will meet the top-K
			criteria and none are selected out.</p>
		<p style="position:absolute;top:467px;left:108px;white-space:nowrap" class="ft01">•&#160;&#160;If you set top-P
			to 0 (or a very small value), most LLM sampling implementations will then&#160;</p>
		<p style="position:absolute;top:494px;left:129px;white-space:nowrap" class="ft03">only consider the most
			probable token to meet the top-P criteria, making temperature and&#160;<br />top-K irrelevant. If you set
			top-P to 1, any token with a nonzero probability of being the&#160;<br />next token will meet the top-P
			criteria, and none are selected out.</p>
		<p style="position:absolute;top:602px;left:108px;white-space:nowrap" class="ft03">As a general starting point, a
			temperature of .2, top-P of .95, and top-K of 30 will give you&#160;<br />relatively coherent results that
			can be creative but not excessively so. If you want especially&#160;<br />creative results, try starting
			with a temperature of .9, top-P of .99, and top-K of 40. And if you&#160;<br />want less creative results,
			try starting with a temperature of .1, top-P of .9, and top-K of 20.&#160;<br />Finally, if your task always
			has a single correct answer (e.g., answering a math problem), start&#160;<br />with a temperature of 0.</p>
		<p style="position:absolute;top:791px;left:108px;white-space:nowrap" class="ft03"><b>NOTE:</b>&#160;With more
			freedom (higher temperature, top-K, top-P, and output tokens), the LLM&#160;<br />might generate text that
			is less relevant.</p>
		<p style="position:absolute;top:872px;left:108px;white-space:nowrap" class="ft03"><b>WARNING:</b>&#160;Have you
			ever seen a response ending with a large amount of filler words? This&#160;<br />is also known as the
			&#34;repetition loop bug&#34;, which is a common issue in Large Language&#160;<br />Models where the model
			gets stuck in a cycle, repeatedly generating the same (filler) word,&#160;<br />phrase, or sentence
			structure, often exacerbated by inappropriate temperature and top-k/</p>
	</div>
</body>

</html>